{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 1\n",
    "# Lending Club Loan Status Analysis\n",
    "## Part 4: Modelling Loan Status: Machine Learning Approach\n",
    "\n",
    "Data Source: Kaggle Dataset -- Lending Club Loan Data  \n",
    "URL: https://www.kaggle.com/wendykan/lending-club-loan-data  \n",
    "Analyst: Eugene Wen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cleaned dataset from previous steps.\n",
    "%run ./py/FE.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 887379 entries, 0 to 887378\n",
      "Data columns (total 33 columns):\n",
      "funded_amnt                    887379 non-null float64\n",
      "term                           887379 non-null object\n",
      "int_rate                       887379 non-null float64\n",
      "annual_inc                     887379 non-null float64\n",
      "verification_status            887379 non-null object\n",
      "purpose                        887379 non-null object\n",
      "addr_state                     887379 non-null object\n",
      "dti                            887379 non-null float64\n",
      "delinq_2yrs                    887379 non-null float64\n",
      "inq_last_6mths                 887379 non-null float64\n",
      "mths_since_last_delinq         887379 non-null float64\n",
      "mths_since_last_record         887379 non-null float64\n",
      "open_acc                       887379 non-null float64\n",
      "pub_rec                        887379 non-null float64\n",
      "revol_bal                      887379 non-null float64\n",
      "revol_util                     887379 non-null float64\n",
      "total_acc                      887379 non-null float64\n",
      "initial_list_status            887379 non-null object\n",
      "out_prncp                      887379 non-null float64\n",
      "total_pymnt                    887379 non-null float64\n",
      "total_rec_int                  887379 non-null float64\n",
      "total_rec_late_fee             887379 non-null float64\n",
      "recoveries                     887379 non-null float64\n",
      "last_pymnt_amnt                887379 non-null float64\n",
      "collections_12_mths_ex_med     887379 non-null float64\n",
      "mths_since_last_major_derog    887379 non-null float64\n",
      "acc_now_delinq                 887379 non-null float64\n",
      "tot_coll_amt                   887379 non-null float64\n",
      "tot_cur_bal                    887379 non-null float64\n",
      "loan_status_simple             887379 non-null object\n",
      "emp_length_yr                  887379 non-null float64\n",
      "home_owner_s                   887379 non-null object\n",
      "cr_hist_yr                     887379 non-null float64\n",
      "dtypes: float64(26), object(7)\n",
      "memory usage: 223.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Quickly check the dataframe loaded in.\n",
    "loan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Set Preparation\n",
    "As we have seen in the previous section, the target (loan_status_simple) is not balaced and including a level Issued that needs to be removed from the target. This level, however, could be used as new data for prediction. \n",
    "\n",
    "For convenience, we will take the following steps to prepare the training, test and prediction sets:  \n",
    "1. Use custom functions to conduct standardization and dummy coding on the dataframe.\n",
    "2. Split status = Issued as predict set. Undersample status = Good observations to 10% (yield 81149 rows) and append to status = Bad to form train_test_set.\n",
    "3. Split the train_test_set into X_train, y_train, X_test and y_test for further modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define std_scaler that takes a dataframe and standardize all numerical columns.\n",
    "# Return updated dataframe.\n",
    "def std_scaler(df):\n",
    "    cols = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    for col in cols: \n",
    "        df[col] = (df[col] - np.mean(df[col]))/np.std(df[col])\n",
    "    return df\n",
    "    \n",
    "# Define dummy_encoder that takes a dataframe and generate (k-1) dummy columns  for all categorical columns.\n",
    "# Return updated dataframe.\n",
    "def dummy_encoder(df):\n",
    "    cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        df.drop(col, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a copy of loan dataframe\n",
    "loan_copy = loan.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process the dataframe using custom functions\n",
    "loan_copy = std_scaler(loan_copy)\n",
    "loan_copy = dummy_encoder(loan_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Undersampling the large category by 10%\n",
    "loan_pred = loan_copy.loc[loan_copy.loan_status_simple_Issued == 1, ]\n",
    "loan_pred.drop([\"loan_status_simple_Good\", \"loan_status_simple_Issued\"], axis = 1, inplace=True)\n",
    "\n",
    "loan_bad = loan_copy.loc[(loan_copy.loan_status_simple_Good == 0) & (loan_copy.loan_status_simple_Issued == 0), ]\n",
    "loan_bad[\"isBad\"] = np.abs(loan_bad.loan_status_simple_Good - 1)\n",
    "loan_bad.drop([\"loan_status_simple_Issued\", \"loan_status_simple_Good\"], axis = 1, inplace=True)\n",
    "\n",
    "loan_good = loan_copy.loc[loan_copy.loan_status_simple_Good == 1, ].sample(frac=0.1)\n",
    "loan_good[\"isBad\"] = np.abs(loan_good.loan_status_simple_Good - 1)\n",
    "loan_good.drop([\"loan_status_simple_Issued\", \"loan_status_simple_Good\"], axis = 1, inplace=True)\n",
    "\n",
    "loan_train_test = pd.concat([loan_good, loan_bad], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For model debugging\n",
    "loan_train_test = loan_train_test.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "all_features = loan_train_test.columns.drop(\"isBad\").tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(loan_train_test[all_features], loan_train_test[\"isBad\"], test_size = 0.3, random_state = 1234) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795199641095\n"
     ]
    }
   ],
   "source": [
    "# Extra Tree Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(X_train, y_train)\n",
    "predictions = etc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance based on Extra Tree Classifier:\n",
      "**************************************************\n",
      "out_prncp                              0.107397\n",
      "last_pymnt_amnt                        0.082758\n",
      "recoveries                             0.064841\n",
      "int_rate                               0.060296\n",
      "total_pymnt                            0.042443\n",
      "funded_amnt                            0.029370\n",
      "total_rec_int                          0.027463\n",
      "revol_util                             0.026363\n",
      "cr_hist_yr                             0.025050\n",
      "dti                                    0.024758\n",
      "tot_cur_bal                            0.023915\n",
      "revol_bal                              0.023335\n",
      "total_rec_late_fee                     0.023234\n",
      "annual_inc                             0.022484\n",
      "open_acc                               0.021879\n",
      "emp_length_yr                          0.021855\n",
      "total_acc                              0.021526\n",
      "initial_list_status_w                  0.021250\n",
      "inq_last_6mths                         0.020580\n",
      "mths_since_last_delinq                 0.019474\n",
      "mths_since_last_major_derog            0.015084\n",
      "tot_coll_amt                           0.014801\n",
      "term_60                                0.014187\n",
      "delinq_2yrs                            0.011709\n",
      "mths_since_last_record                 0.011385\n",
      "verification_status_Source Verified    0.011041\n",
      "home_owner_s_RENT                      0.010433\n",
      "verification_status_Verified           0.009762\n",
      "pub_rec                                0.009721\n",
      "addr_state_CA                          0.009572\n",
      "                                         ...   \n",
      "addr_state_AR                          0.001933\n",
      "collections_12_mths_ex_med             0.001697\n",
      "addr_state_NM                          0.001578\n",
      "addr_state_KS                          0.001557\n",
      "purpose_medical                        0.001534\n",
      "addr_state_KY                          0.001468\n",
      "purpose_moving                         0.001448\n",
      "addr_state_MS                          0.001434\n",
      "addr_state_WV                          0.001405\n",
      "acc_now_delinq                         0.001268\n",
      "addr_state_HI                          0.001240\n",
      "purpose_vacation                       0.001222\n",
      "addr_state_DE                          0.001020\n",
      "addr_state_RI                          0.000990\n",
      "addr_state_NH                          0.000967\n",
      "purpose_house                          0.000931\n",
      "addr_state_SD                          0.000861\n",
      "purpose_wedding                        0.000757\n",
      "addr_state_MT                          0.000693\n",
      "addr_state_WY                          0.000514\n",
      "addr_state_DC                          0.000436\n",
      "addr_state_VT                          0.000332\n",
      "purpose_renewable_energy               0.000262\n",
      "addr_state_NE                          0.000251\n",
      "purpose_educational                    0.000099\n",
      "addr_state_ME                          0.000073\n",
      "addr_state_ND                          0.000032\n",
      "home_owner_s_OTHER                     0.000030\n",
      "addr_state_IA                          0.000000\n",
      "addr_state_ID                          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "feature_importance = pd.Series(etc.feature_importances_, index=all_features).sort_values(ascending=False)\n",
    "print(\"Feature importance based on Extra Tree Classifier:\")\n",
    "print(\"**************************************************\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_features = feature_importance3[feature_importance3 > 0.05].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831090174966\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning and Pipeline: Choose the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select and Tune Different Algorithms: LR, RF, SVM, Naive Bayesian Classifier, XGBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model selection function\n",
    "def choose_model(df, feature_list, target_df):\n",
    "    X = df[feature_list]\n",
    "    y = target_df\n",
    "    \n",
    "    dict_list = [\n",
    "        {\n",
    "            \"name\": \"LogisticRegression\",\n",
    "            \"estimator\": LogisticRegression(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "                }\n",
    "        },\n",
    "\n",
    "        \n",
    "#        {\n",
    "#            \"name\": \"RandomForestClassifier\",\n",
    "#            \"estimator\": RandomForestClassifier(),\n",
    "#            \"hyperparameters\":\n",
    "#                {\n",
    "#                    \"n_estimators\": [4,6,9],\n",
    "#                    \"criterion\":[\"entropy\", \"gini\"],\n",
    "#                    \"max_depth\": [2,5,10],\n",
    "#                    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "#                    \"min_samples_leaf\":[1,5,8],\n",
    "#                    \"min_samples_split\":[2,3,5]\n",
    "#                }\n",
    "#        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"SupportVectorMachine\",\n",
    "            \"estimator\": SVC(),\n",
    "            \"hyperparameters\":\n",
    "                {\n",
    "                    \"kernel\": [\"linear\"],\n",
    "                    \"C\": [1, 2]\n",
    "                }\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"name\": \"NaiveBayesian\",\n",
    "            \"estimator\": GaussianNB(),\n",
    "            \"hyperparameters\": None\n",
    "        }]\n",
    "    for dict in dict_list:\n",
    "        print(dict[\"name\"])\n",
    "        grid = GridSearchCV(dict[\"estimator\"], param_grid=dict[\"hyperparameters\"], cv=10)\n",
    "        grid.fit(X, y)\n",
    "        dict[\"best_params\"] = grid.best_params_\n",
    "        dict[\"best_score\"] = grid.best_score_\n",
    "        dict[\"best_estimator\"] = grid.best_estimator_\n",
    "        print(grid.best_params_)\n",
    "        print(grid.best_score_)\n",
    "    \n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "{'solver': 'newton-cg'}\n",
      "0.781923076923\n",
      "SupportVectorMachine\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "0.784903846154\n",
      "NaiveBayesian\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-35e821ad9610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mselected_MLmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-95f5baede0f2>\u001b[0m in \u001b[0;36mchoose_model\u001b[0;34m(df, feature_list, target_df)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"estimator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hyperparameters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"best_params\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m    923\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m    924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "selected_MLmodel = choose_model(X_train, opt_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the best model is random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831314490803\n"
     ]
    }
   ],
   "source": [
    "# Score x_test dataset\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train[opt_features], y_train)\n",
    "predictions_opt = rfc.predict(X_test[opt_features])\n",
    "accuracy_opt = accuracy_score(y_test, predictions_opt)\n",
    "print(accuracy_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-067592282978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mopt_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;31m#roc_auc = auc(fpr, tpr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \"\"\"\n\u001b[1;32m    504\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 505\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m              \u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m              array_equal(classes, [1]))):\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance using ROC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = rfc.predict_proba(X_test[opt_features])[:,1]\n",
    "fpr, tpr, th = roc_curve(y_test, y_score)\n",
    "#roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  1. ,  0.1, ...,  1. ,  0.6,  0. ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
